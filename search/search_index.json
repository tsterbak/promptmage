{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"PromptMage","text":"Welcome to PromptMage <p>         PromptMage is a python framework to simplify the development of complex, multi-step applications based on LLMs.         </p> Get Started Learn More <p>WARNING</p> <p>This application is currently in alpha state and under active development. Please be aware that the API and features may change at any time.</p> <p> <ul> <li> <p> Set up in 5 minutes</p> <p>Get PromptMage up and running quickly with simple installation steps. Deploy locally or on your server with ease.</p> <p> Getting started</p> </li> <li> <p> Version Control Built-in</p> <p>Track prompt development with integrated version control, making collaboration and iteration seamless.</p> <p> Learn more</p> </li> <li> <p> Prompt Playground</p> <p>Test, compare, and refine prompts in an intuitive interface designed for rapid iteration.</p> <p> Playground</p> </li> <li> <p> Auto-generated API</p> <p>Leverage a FastAPI-powered, automatically created API for easy integration and deployment.</p> <p> API Documentation</p> </li> <li> <p> Evaluation Mode</p> <p>Assess prompt performance through manual and automatic testing, ensuring reliability before deployment.</p> <p> Evaluation Guide</p> </li> <li> <p> More to Come</p> <p>Stay tuned for upcoming features and enhancements as we continue to evolve PromptMage.</p> <p> Roadmap</p> </li> </ul> <p></p>"},{"location":"#about-the-project","title":"About the Project","text":"<p>PromptMage is a python framework to simplify the development of complex, multi-step applications based on LLMs. It is designed to offer an intuitive interface that simplifies the process of creating and managing LLM workflows as a self-hosted solution. PromptMage facilitates prompt testing and comparison, and incorporates version control features to help users track the development of their prompts. Suitable for both small teams and large enterprises, PromptMage seeks to improve productivity and foster the practical use of LLM technology.</p> <p>The approach with PromptMage is to provide a pragmatic solution that bridges the current gap in LLM workflow management. We aim to empower developers, researchers, and organizations by making LLM technology more accessible and manageable, thereby supporting the next wave of AI innovations.</p> <p>Take the walkthrough to see what you can do with PromptMage.</p>"},{"location":"#philosophy","title":"Philosophy","text":"<ul> <li>Integrate the prompt playground into your workflow for fast iteration</li> <li>Prompts as first-class citizens with version control and collaboration features</li> <li>Manual and automatic testing and validation of prompts</li> <li>Easy sharing of results with domain experts and stakeholders</li> <li>build-in, automatically created API with fastAPI for easy integration and deployment</li> <li>Type-hint everything for automatic inference and validation magic</li> </ul>"},{"location":"#projects-using-promptmage","title":"Projects using PromptMage","text":"<ul> <li>product-review-research: An AI webapp build with PromptMage to provide in-depth analysis for products by researching trustworthy online reviews. </li> </ul>"},{"location":"#development","title":"Development","text":"<p>To develop PromptMage, check out the DEVELOPMENT.md file.</p>"},{"location":"#contributing","title":"Contributing","text":"<p>We welcome contributions from the community!</p> <p>If you're interested in improving PromptMage, you can contribute in the following ways: * Reporting Bugs: Submit an issue in our repository, providing a detailed description of the problem and steps to reproduce it. * Improve documentation: If you find any errors or have suggestions for improving the documentation, please submit an issue or a pull request. * Fixing Bugs: Check out our list of open issues and submit a pull request to fix any bugs you find. * Feature Requests: Have ideas on how to make PromptMage better? We'd love to hear from you! Please submit an issue, detailing your suggestions. * Pull Requests: Contributions via pull requests are highly appreciated. Please ensure your code adheres to the coding standards of the project, and submit a pull request with a clear description of your changes.</p> <p>To ensure a smooth contribution process, please follow these guidelines: * create an issue before submitting a pull request to discuss the changes you'd like to make. This helps us ensure that your contribution aligns with the project's goals and prevents duplicate work. * follow the coding standards of the project. Check the DEVELOPMENT.md file for more information.</p> <p>Make sure to check if your issue or PR has already been fixed or implemented before opening a new one!</p>"},{"location":"#contact","title":"Contact","text":"<p>For any inquiries or further information, feel free to reach out at promptmage@tobiassterbak.com.</p>"},{"location":"#acknowledgements","title":"\u2764\ufe0f Acknowledgements","text":"<p>This project was supported by</p> <p> </p>"},{"location":"getting-started/","title":"Getting Started","text":""},{"location":"getting-started/#installation","title":"Installation","text":"<p>To install promptmage, run the following command:</p> <pre><code>pip install promptmage \n</code></pre>"},{"location":"getting-started/#annotated-code-example","title":"Annotated Code Example","text":"<p>Here is an example of how to use promptmage in your application:</p> <pre><code>from promptmage import PromptMage, Prompt, MageResult\n\n# Create a new promptmage instance\nmage = PromptMage(#(1)!\n    name=\"example\",#(2)!\n)\n</code></pre> <ol> <li>The <code>PromptMage</code> class is the main class of promptmage. It is used store all the information about the flow and to run the flow.</li> <li>The <code>name</code> parameter is used to give the promptmage instance a unique name. This allows to run multiple promptmage instances in parallel.</li> </ol> <p>Steps are the building blocks of a flow. They are used to define the different parts of the flow and to connect them together. A step is just a python function with the <code>@mage.step()</code> decorator which returns a <code>MageResult</code>. Here is an example of how to create a step:</p> <pre><code>@mage.step(\n    name=\"step1\", #(1)!\n    prompt_name=\"prompt1\", #(2)!\n    initial=True #(3)!\n)\ndef step1(question: str, prompt: Prompt) -&gt; MageResult: #(4)!\n    response = client.chat.completions.create( #(5)!\n        model=\"gpt-4o-mini\",\n        messages=[\n            {\"role\": \"system\", \"content\": prompt.system},\n            {\n                \"role\": \"user\",\n                \"content\": prompt.user.format(question=question),\n            },\n        ],\n    )\n    answer = response.choices[0].message.content\n    return MageResult(\n        next_step=None, #(6)!\n        result=answer\n    )\n</code></pre> <ol> <li>The <code>name</code> parameter is used to give the step a unique name.</li> <li>The <code>prompt_name</code> parameter is used to specify the name of the prompt that should be used for this step.</li> <li>The <code>initial</code> parameter is used to specify if this is the initial step of the flow.</li> <li>The <code>step1</code> function is a step that takes a question and a prompt as input and returns a <code>MageResult</code> with the result of the step and the name of the next step to run. The prompt is managed by the promptmage instance and is automatically passed to the step.</li> <li>The step uses the OpenAI API to generate a response to the question using the prompt.</li> <li>The <code>next_step</code> parameter is used to specify the name of the next step to run. If <code>None</code> is returned, the flow will stop.</li> </ol>"},{"location":"getting-started/#usage","title":"Usage","text":"<p>Put the above code in a file called <code>flow.py</code> and setup the OpenAI client. To run the flow with promptmage, run the following command:</p> <pre><code>promptmage run flow.py\n</code></pre> <p>This will start the promptmage server and run the flow at the given path. You can now access the promptmage interface at <code>http://localhost:8000/gui/</code>.</p>"},{"location":"getting-started/#usage-with-a-remote-backend-server","title":"Usage with a remote backend server","text":"<p>For a production setup and collaborative usage with teams you can run the promptmage server with a remote backend. To run the remote backend on a remote server, run the following command:</p> <pre><code>promptmage serve --port 8021\n</code></pre> <p>To connect your promptmage script to the remote backend, you need to add the <code>remote</code> url to the PromptMage instance of your script:</p> <pre><code>mage = PromptMage(\n  name=\"example\",\n  remote=\"http://localhost:8021\" #(1)!\n)\n</code></pre> <p>Now you can run your script and the promptmage server will use the remote backend to run the flow and store the results.</p> <ol> <li>The <code>remote</code> parameter is used to specify the URL of the remote backend to use. If this is set, the <code>PromptMage</code> instance will use the remote backend instead of the local one.</li> </ol>"},{"location":"getting-started/#gui-walkthrough","title":"GUI walkthrough","text":"<p>The promptmage interface is divided into four main sections: the flow playground, the run history, the prompt repository, and the evaluation section.</p>"},{"location":"getting-started/#flow-playground","title":"Flow playground","text":"Initial flow playground for the example flow. Edit the step prompt of step 1. After the run you can see the execution graph and the results."},{"location":"getting-started/#run-history","title":"Run history","text":"Here you can see all your runs and the results. By clicking on a run, you can look at the details."},{"location":"getting-started/#prompt-repository","title":"Prompt repository","text":"You can see all your prompts and versions in the prompts repository."},{"location":"getting-started/#more-examples","title":"More examples","text":"<p>Have a look at the examples in the examples folder to see how to use promptmage in your application or workflow.</p>"},{"location":"getting-started/#use-with-docker","title":"Use with Docker","text":"<p>You can find an usage example with docker here: Docker example.</p>"},{"location":"license/","title":"License","text":"<p>This project is licensed under the MIT License - see the LICENSE.md file for details. Original development by Tobias Sterbak.</p>"},{"location":"reference/","title":"API Reference","text":"<p>This page contains the API reference with the most important classes and methods of promptmage.</p>"},{"location":"reference/#promptmage-cli","title":"PromptMage CLI","text":"<p>The <code>promptmage</code> CLI is the command line interface to run the promptmage server and interact with the promptmage backend.</p>"},{"location":"reference/#version","title":"version","text":"<p>Show the installed promptmage version.</p> <p>Usage: <pre><code>promptmage version\n</code></pre></p>"},{"location":"reference/#run","title":"run","text":"<p>Run a flow with the given path. A flow is a python script that defines the flow of the promptmage application.</p> <p>Usage: <pre><code>promptmage run &lt;path-to-flow&gt;\n</code></pre></p> <p>Available options: - <code>--port</code> (<code>int</code>):   The port to run the server on. Default is <code>8000</code>. - <code>--host</code> (<code>str</code>):   The host to run the server on. Default is <code>localhost</code>.</p>"},{"location":"reference/#serve","title":"serve","text":"<p>Start the promptmage backend server.</p> <p>Usage: <pre><code>promptmage serve\n</code></pre></p> <p>Available options: - <code>--port</code> (<code>int</code>):   The port to run the server on. Default is <code>8021</code>. - <code>--host</code> (<code>str</code>):   The host to run the server on. Default is <code>localhost</code>.</p>"},{"location":"reference/#export","title":"export","text":"<p>Export the promptmage database to json.</p> <p>Usage: <pre><code>promptmage export --filename &lt;filename&gt;\n</code></pre></p> <p>Available options: - <code>--filename</code> (<code>str</code>):   The filename to export the database to. - <code>--runs</code> (<code>bool</code>):   Whether to export the runs as well. Default is <code>False</code>. - <code>--prompts</code> (<code>bool</code>):   Whether to export the prompts as well. Default is <code>False</code>.</p>"},{"location":"reference/#backup","title":"backup","text":"<p>Backup the promptmage database to a json file.</p> <p>Usage: <pre><code>promptmage backup --json_path &lt;json_path&gt;\n</code></pre></p> <p>Available options: - <code>--json_path</code> (<code>str</code>):   The path to the json file to backup the database to.</p>"},{"location":"reference/#restore","title":"restore","text":"<p>Restore the promptmage database from a json file.</p> <p>Warning</p> <p>This will ask for confirmation before restoring and will overwrite the current database.</p> <p>Usage: <pre><code>promptmage restore --json_path &lt;json_path&gt;\n</code></pre></p> <p>Available options: - <code>--json_path</code> (<code>str</code>):   The path to the json file to restore the database from.</p>"},{"location":"reference/#promptmage-class","title":"PromptMage <code>class</code>","text":"<p>The <code>PromptMage</code> class is the main class of promptmage. It is used store all the information about the flow and to run the flow.</p>"},{"location":"reference/#attributes","title":"Attributes","text":"<ul> <li> <p>name (<code>str</code>):   The name of the <code>PromptMage</code> instance.</p> </li> <li> <p>remote (<code>str</code>):   The URL of the remote backend to use. If this is set, the <code>PromptMage</code> instance will use the remote backend instead of the local one.</p> </li> <li> <p>available_models (<code>List[str]</code>):   A list of available models to use for the flow.</p> </li> </ul> <p>Info</p> <p>The available models are just strings that are passed to the step function to specify the model to use for the completion. You have to handle the model selection in the step function.</p>"},{"location":"reference/#methods","title":"Methods","text":""},{"location":"reference/#promptmagestep-decorator","title":"<code>PromptMage.step()</code> <code>decorator</code>","text":"<p>Decorator to define a step in the flow.</p> <p>Tip</p> <p>A step is just a python function with the <code>@mage.step()</code> decorator which returns a <code>MageResult</code>.</p>"},{"location":"reference/#arguments","title":"Arguments","text":"<ul> <li> <p>name (<code>str</code>):   The name of the step.</p> </li> <li> <p>prompt_name (<code>str</code>):   The name of the prompt to use for this step.</p> </li> <li> <p>initial (<code>bool</code>):   Whether this is the initial step of the flow.</p> </li> <li> <p>one_to_many (<code>bool</code>):   Whether this step should be run for each item in the input list.</p> </li> <li> <p>many_to_one (<code>bool</code>):   Whether this step should be run for each item in the input list and the results should be combined.</p> </li> </ul>"},{"location":"reference/#mageresult-class","title":"MageResult <code>class</code>","text":"<p>The <code>MageResult</code> class is used to return the result of a step.</p>"},{"location":"reference/#attributes_1","title":"Attributes","text":"<ul> <li> <p>next_step (<code>str | None</code>):   The name of the next step to run.</p> </li> <li> <p>error (<code>str | None</code>):   An error message if the step failed.</p> </li> <li> <p>**kwargs (<code>Any</code>):   All additional keyword arguments are stored as the result by name and can be used by the next step.</p> </li> </ul>"},{"location":"reference/#prompt-class","title":"Prompt <code>class</code>","text":"<p>The <code>Prompt</code> class is used to store the prompt information.</p> <p>Warning</p> <p>This class should not be created by the user. It is automatically created by the <code>PromptMage</code> instance and only used to pass the prompt to the step functions and retrieve the prompts from the database.</p>"},{"location":"reference/#attributes_2","title":"Attributes","text":"<ul> <li> <p>system (<code>str</code>):   The system prompt.</p> </li> <li> <p>user (<code>str</code>):   The user prompt.</p> </li> </ul>"},{"location":"roadmap/","title":"Roadmap","text":""},{"location":"roadmap/#2024","title":"2024","text":""},{"location":"roadmap/#august","title":"August","text":"<ul> <li> Implement a dynamic execution graph for flows</li> <li> Implement an evaluation mode for applications</li> </ul>"},{"location":"roadmap/#september","title":"September","text":"<ul> <li> Implement a remote backend for PromptMage</li> <li> Improve error handling and reporting</li> </ul>"},{"location":"roadmap/#october","title":"October","text":"<ul> <li> More complex use-case examples</li> <li> Implement a robust task queue for LLM calls</li> </ul>"},{"location":"roadmap/#november","title":"November","text":"<ul> <li> Implement automatic evaluation with llm-as-a-judge</li> </ul>"},{"location":"roadmap/#december","title":"December","text":"<ul> <li> more to come!</li> </ul>"},{"location":"roadmap/#2025","title":"2025","text":""},{"location":"tutorial/","title":"Tutorial","text":"<p>Welcome to the PromptMage tutorial! This tutorial will guide you through the basics of PromptMage, and show you how integrate it into your own LLM project.</p>"},{"location":"tutorial/#use-case","title":"Use case","text":"<p>For this tutorial, we want to build a simple multi-step LLM application. It contains multiple dependent steps, where the output of one step is used as the input for the next step. The application will be used to summarize an input text with extracting facts to summarize from.</p> <p>The application will have the following steps:</p> <ul> <li>Step 1: Extract facts from a given text</li> <li>Step 2: Summarize the text using the extracted facts</li> </ul> <p>We assume all the steps are implemented as separate Python functions that take input and return output in one python file <code>summarizer.py</code>.</p>"},{"location":"tutorial/#step-1-install-promptmage","title":"Step 1: Install PromptMage","text":"<p>First, we need to install PromptMage. You can install PromptMage using pip:</p> <pre><code>pip install promptmage\n</code></pre> <p>It is recommended to install PromptMage in a virtual environment to avoid conflicts with other packages.</p>"},{"location":"tutorial/#step-2-add-promptmage-to-your-project","title":"Step 2: Add PromptMage to your project","text":"<p>First, you need to add PromptMage to your project. You do that by adding the following to your <code>summarizer.py</code> file:</p> <pre><code># Create a new PromptMage instance\nmage = PromptMage(name=\"fact-summarizer\")\n</code></pre> <p>Next, you need to define the prompts and dependencies between the steps. You can do that by adding the following code to the functions in the <code>summarizer.py</code> file:</p> <pre><code>@mage.step(name=\"extract\", prompt_name=\"extract_facts\", initial=True)\ndef extract_facts(article: str, prompt: Prompt) -&gt; str:\n    # &lt;your application code here&gt;\n    return MageResult(facts=facts, next_step=\"summarize\")\n</code></pre> <p>As a first step, this needs to be the initial step, so we set the <code>initial</code> parameter to <code>True</code>. This will be the first step that is executed when the application is run. Every step needs to return a <code>MageResult</code> object, which contains the output of the step and the name of the next step to be executed. In this case, the next step is the <code>summarize</code> step. Note, that you can also return a list of <code>MageResult</code> objects if you want to execute multiple steps in parallel.</p> <pre><code>@mage.step(name=\"summarize\", prompt_name=\"summarize_facts\")\ndef summarize_facts(facts: str, prompt: Prompt) -&gt; str:\n    # &lt;your application code here&gt;\n    return MageResult(summary=summary)\n</code></pre> <p>If the next_step is not specified, the step will be considered a terminal step and the application will stop after executing this step.</p> <p>Now you can access the prompts within the step functions using the <code>prompt</code> argument. The <code>prompt</code> argument is an instance of the <code>Prompt</code> class, which provides methods to interact with the prompt. By default we have a system and a user prompt available by <code>prompt.system</code> and <code>prompt.user</code> respectively. The prompts are later created in the web UI.</p> <p>You don't need to worry about saving the prompts and data, PromptMage will take care of that for you.</p>"},{"location":"tutorial/#step-3-run-the-application","title":"Step 3: Run the application","text":"<p>Now you can run the application by </p> <pre><code>promptmage run summarizer.py\n</code></pre> <p>This will start the PromptMage web UI, where you can interact with the prompts and run and see the output of the steps. You can access the web UI at <code>http://localhost:8000/gui/</code>.</p> <p>More examples can be found in the examples folder.</p>"},{"location":"walkthrough/","title":"Walkthrough","text":""},{"location":"walkthrough/#launching-the-application","title":"Launching the application","text":"<p>After you installed promptmage and added it to your project following the tutorial, you can now run the application and interact with it in the web UI.</p> <p>To run the application, you can use the following command:</p> <pre><code>promptmage run summarizer.py\n</code></pre> <p>This will start the promptmage server and run the application at the given path.</p>"},{"location":"walkthrough/#accessing-the-api","title":"Accessing the API","text":"<p>PromptMage automatically creates an API for your application using FastAPI. You can access the API at <code>http://localhost:8000/api/</code> and the Swagger documentation at <code>http://localhost:8000/docs/</code>.</p> <p></p> <p>You can use the API to interact with your application programmatically or integrate it into other services.</p>"},{"location":"walkthrough/#interacting-with-the-web-ui","title":"Interacting with the web UI","text":"<p>You can access the web UI at <code>http://localhost:8000/gui/</code>. Here you can interact with the prompts and see the output of the steps.</p>"},{"location":"walkthrough/#application-overview","title":"Application Overview","text":"<p>The application overview shows all available flows.</p> <p></p>"},{"location":"walkthrough/#flow-overview","title":"Flow Overview","text":"<p>The flow overview shows all steps of the flow and their status as well as an execution graph for the flow once executed.</p> <p></p>"},{"location":"walkthrough/#step-interaction","title":"Step interaction","text":"<p>You can interact with the steps by clicking on them. This will expand the step and show the prompts and the output of the step. This also allows you to manually run the step and tweak the input and prompts.</p> <p></p>"},{"location":"walkthrough/#runs-page","title":"Runs page","text":"<p>The runs page shows all runs of the application and allows you to see the output of the steps for each run.</p> <p></p> <p>You can also replay runs to see the output of the steps and the prompts that were used during the run.</p>"},{"location":"walkthrough/#prompt-repository","title":"Prompt repository","text":"<p>The prompt repository allows you to manage your prompts. You can create new prompt versions, edit existing prompts, and delete prompts. You can also see the history of a prompt and see which runs used the prompt.</p> <p></p>"},{"location":"walkthrough/#conclusion","title":"Conclusion","text":"<p>This concludes the walkthrough of PromptMage. You have seen how to install and use PromptMage, how to create a simple application, and how to interact with the web UI. You can now integrate PromptMage into your workflow and use it to build and test your applications faster and more efficiently.</p>"}]}